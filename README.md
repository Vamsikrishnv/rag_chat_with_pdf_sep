RAG Chat with PDFs

An interactive Retrieval-Augmented Generation (RAG) app built with LangChain, FAISS, and Streamlit.
Upload your PDFs and ask questions â€” get precise answers with citations.

ğŸš€ Features

ğŸ“‚ PDF Upload & Indexing â€“ add personal or work PDFs easily

ğŸ§© Chunking Strategies â€“ recursive, fixed, or token-based splits

ğŸ” Retrieval Modes â€“ Similarity, MMR (diverse), Hybrid (BM25 + embeddings)

ğŸ¯ Cross-Encoder Rerank â€“ improves answer relevance

ğŸ“Š Evaluation Tab â€“ compare retrieval modes across questions

ğŸ’¾ Persistent FAISS Storage â€“ incremental updates or full reindex

ğŸ’¬ Chat UI â€“ answers with citations, sources table, CSV export

ğŸ— Architecture

Streamlit â€“ UI for chat & controls

LangChain â€“ document loading, splitting, retrievers

FAISS â€“ vector database for embeddings

BM25 Retriever â€“ sparse keyword search

Hybrid Fusion (RRF) â€“ merges dense + sparse results

OpenAI / HuggingFace Embeddings â€“ flexible embeddings provider

âš™ï¸ Setup
1. Clone the repo
git clone https://github.com/Vamsikrishnv/rag_chat_with_pdf_sep.git
cd rag_chat_with_pdf_sep

2. Create a virtual environment
python -m venv .venv
# Activate
# Windows (PowerShell)
.venv\Scripts\Activate.ps1
# macOS/Linux
source .venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

4. Configure API Keys

Create a .env file (already .gitignored):

OPENAI_API_KEY=your-key-here
HF_MODEL=sentence-transformers/all-MiniLM-L6-v2

5. Run Streamlit app
streamlit run streamlit_app.py


ğŸ‘‰ Open http://localhost:8501
 in your browser.

ğŸ–¼ï¸ Demo


ğŸ§ª Example Usage

Upload your resume PDF

Ask: â€œWhat projects demonstrate RAG expertise?â€

Get an answer with citations pointing to exact pages

ğŸ”® Next Up

 Multi-file cross-PDF search

 Auth & user sessions

 Cloud deployment (Streamlit Cloud / Docker)

ğŸ‘¨â€ğŸ’» Author

Vamshi Krishna
Full-Stack & GenAI Engineer |
